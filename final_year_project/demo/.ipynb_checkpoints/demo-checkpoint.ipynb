{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer as Summarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = \"english\"\n",
    "SENTENCES_COUNT = 7\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 )  A top party leader, who spoke on the condition of anonymity, said they are exploring the possibility of deferring assembly elections of some states by a few months and advancing some others to ensure they are held simultaneously with the Lok Sabha polls.\n",
      "1 )  A top party leader spoke condition anonymity said exploring possibility deferring assembly elections states months advancing others ensure held simultaneously Lok Sabha polls \n",
      "-------\n",
      "2 )  Assembly elections in Andhra Pradesh, Odisha and Telangana are anyway scheduled to be held with the parliamentary polls, he said.\n",
      "2 )  Assembly elections Andhra Pradesh Odisha Telangana anyway scheduled held parliamentary polls said \n",
      "-------\n",
      "3 )  Another state where talks of advancing assembly elections are doing the rounds is Bihar, where they are due in 2020 end.\n",
      "3 )  Another state talks advancing assembly elections rounds Bihar due 2020 end \n",
      "-------\n",
      "4 )  There is a view within the BJP that holding assembly elections of as many states as possible with the Lok Sabha polls will be a positive plank in its favour as Prime Minister Narendra Modi has repeatedly emphasised his support to the idea.\n",
      "4 )  There view within BJP holding assembly elections many states possible Lok Sabha polls positive plank favour Prime Minister Narendra Modi repeatedly emphasised support idea \n",
      "-------\n",
      "5 )  With the opposition parties like the Congress being against the idea, the government is not in a position to effect the constitutional amendment that the exercise of holding assembly and Lok Sabha polls simultaneously would require.\n",
      "5 )  With opposition parties like Congress idea government position effect constitutional amendment exercise holding assembly Lok Sabha polls simultaneously would require \n",
      "-------\n",
      "6 )  By clubbing assembly elections in states ruled mostly by the BJP, the party would send a message that it means business, its leaders said.\n",
      "6 )  By clubbing assembly elections states ruled mostly BJP party would send message means business leaders said \n",
      "-------\n",
      "7 )  Amit Shah wrote a letter to the Law Commission favouring simultaneous elections (File)\n",
      "7 )  Amit Shah wrote letter Law Commission favouring simultaneous elections File \n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.ndtv.com/india-news/bjp-exploring-possibility-of-simultaneous-polls-in-11-states-in-2019-1899962?pfrom=home-livetv\"\n",
    "    parser = HtmlParser.from_url(url, Tokenizer(LANGUAGE))\n",
    "    # or for plain text files\n",
    "    # parser = PlaintextParser.from_file(\"document.txt\", Tokenizer(LANGUAGE))\n",
    "    stemmer = Stemmer(LANGUAGE)\n",
    "\n",
    "    summarizer = Summarizer(stemmer)\n",
    "    summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "    \n",
    "    counter = 1\n",
    "    corpus = []\n",
    "    corpus_new = []\n",
    "    for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "        print(counter , \") \",  sentence)\n",
    "        corpus.append(str(sentence).split(\" \"))\n",
    "        corpus_new.append(str(sentence))\n",
    "        \n",
    "        word_tokens = word_tokenize(str(sentence))\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "        filtered_sentence1 = \"\"\n",
    " \n",
    "        for w in word_tokens:\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence1 += str(w) + \" \"\n",
    " \n",
    "        print(counter , \") \",  filtered_sentence1)\n",
    "        print(\"-------\")\n",
    "        \n",
    "        counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'top', 'party', 'leader,', 'who', 'spoke', 'on', 'the', 'condition', 'of', 'anonymity,', 'said', 'they', 'are', 'exploring', 'the', 'possibility', 'of', 'deferring', 'assembly', 'elections', 'of', 'some', 'states', 'by', 'a', 'few', 'months', 'and', 'advancing', 'some', 'others', 'to', 'ensure', 'they', 'are', 'held', 'simultaneously', 'with', 'the', 'Lok', 'Sabha', 'polls.'], ['Assembly', 'elections', 'in', 'Andhra', 'Pradesh,', 'Odisha', 'and', 'Telangana', 'are', 'anyway', 'scheduled', 'to', 'be', 'held', 'with', 'the', 'parliamentary', 'polls,', 'he', 'said.'], ['Another', 'state', 'where', 'talks', 'of', 'advancing', 'assembly', 'elections', 'are', 'doing', 'the', 'rounds', 'is', 'Bihar,', 'where', 'they', 'are', 'due', 'in', '2020', 'end.'], ['There', 'is', 'a', 'view', 'within', 'the', 'BJP', 'that', 'holding', 'assembly', 'elections', 'of', 'as', 'many', 'states', 'as', 'possible', 'with', 'the', 'Lok', 'Sabha', 'polls', 'will', 'be', 'a', 'positive', 'plank', 'in', 'its', 'favour', 'as', 'Prime', 'Minister', 'Narendra', 'Modi', 'has', 'repeatedly', 'emphasised', 'his', 'support', 'to', 'the', 'idea.'], ['With', 'the', 'opposition', 'parties', 'like', 'the', 'Congress', 'being', 'against', 'the', 'idea,', 'the', 'government', 'is', 'not', 'in', 'a', 'position', 'to', 'effect', 'the', 'constitutional', 'amendment', 'that', 'the', 'exercise', 'of', 'holding', 'assembly', 'and', 'Lok', 'Sabha', 'polls', 'simultaneously', 'would', 'require.'], ['By', 'clubbing', 'assembly', 'elections', 'in', 'states', 'ruled', 'mostly', 'by', 'the', 'BJP,', 'the', 'party', 'would', 'send', 'a', 'message', 'that', 'it', 'means', 'business,', 'its', 'leaders', 'said.'], ['Amit', 'Shah', 'wrote', 'a', 'letter', 'to', 'the', 'Law', 'Commission', 'favouring', 'simultaneous', 'elections', '(File)']]\n"
     ]
    }
   ],
   "source": [
    "print (corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'top', 'party', 'leader,', 'who', 'spoke', 'on', 'the', 'condition', 'of', 'anonymity,', 'said', 'they', 'are', 'exploring', 'possibility', 'deferring', 'assembly', 'elections', 'some', 'states', 'by', 'a', 'few', 'months', 'and', 'advancing', 'others', 'to', 'ensure', 'held', 'simultaneously', 'with', 'Lok', 'Sabha', 'polls.', 'Assembly', 'in', 'Andhra', 'Pradesh,', 'Odisha', 'Telangana', 'anyway', 'scheduled', 'be', 'parliamentary', 'polls,', 'he', 'said.', 'Another', 'state', 'where', 'talks', 'doing', 'rounds', 'is', 'Bihar,', 'due', '2020', 'end.', 'There', 'view', 'within', 'BJP', 'that', 'holding', 'as', 'many', 'possible', 'polls', 'will', 'positive', 'plank', 'its', 'favour', 'Prime', 'Minister', 'Narendra', 'Modi', 'has', 'repeatedly', 'emphasised', 'his', 'support', 'idea.', 'With', 'opposition', 'parties', 'like', 'Congress', 'being', 'against', 'idea,', 'government', 'not', 'position', 'effect', 'constitutional', 'amendment', 'exercise', 'would', 'require.', 'By', 'clubbing', 'ruled', 'mostly', 'BJP,', 'send', 'message', 'it', 'means', 'business,', 'leaders', 'Amit', 'Shah', 'wrote', 'letter', 'Law', 'Commission', 'favouring', 'simultaneous', '(File)']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing \n",
    "\n",
    "model = Word2Vec(corpus, size=20, window=10, min_count=1, workers=multiprocessing.cpu_count(), sample = 1e-3, seed=1)             \n",
    "words = list(model.wv.vocab)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02389417  0.0008584   0.00998142 -0.02239298  0.01020494  0.00959695\n",
      "  0.0214609   0.00666328  0.01906509  0.01641103  0.0160549  -0.01231361\n",
      "  0.01746809 -0.01578444  0.01104337 -0.01694796  0.02231242 -0.01309625\n",
      "  0.01515841  0.00505506]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ranojoy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model['BJP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02389417  0.0008584   0.00998142 -0.02239298  0.01020494  0.00959695\n",
      "  0.0214609   0.00666328  0.01906509  0.01641103  0.0160549  -0.01231361\n",
      "  0.01746809 -0.01578444  0.01104337 -0.01694796  0.02231242 -0.01309625\n",
      "  0.01515841  0.00505506]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ranojoy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model.save('model.bin')\n",
    "new_model = Word2Vec.load('model.bin')\n",
    "print(new_model['BJP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ranojoy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X = model[model.wv.vocab]\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "pyplot.scatter(result[:, 0], result[:, 1])\n",
    "words = list(model.wv.vocab)\n",
    "for i, word in enumerate(words):\n",
    "\tpyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) We can only tarin on good news as they are easily available. \n",
    "2) If fake news is needed then vectors of good news can be adulterated.\n",
    "3) Fake news can be generated using GAN (generative adverisal network).\n",
    "\n",
    "4) Vectorise news - \n",
    "    4.1) From google api get current hot news\n",
    "    4.2) Sumarise them to reduce the input vector size.\n",
    "    4.3) Vectorise them using google Woed2Vec. (Can train it on my own corpus)\n",
    "    \n",
    "5) Assume each news article as one large vector that will go as an input to the LSTM.\n",
    "6) So, each word will have n-number of features from Word2Vec.\n",
    "7) Therefor the input ector size wil be sizeof_sentence * n.\n",
    "8) The input vector size must be constant as sizeof_sentense must be constant.\n",
    "\n",
    "9) To get one size for multiple documents it can be done rndomly or based on some statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(corpus)]\n",
    "model = Doc2Vec(documents,\n",
    "                vector_size=20,\n",
    "                window=5,\n",
    "                min_count=1,\n",
    "                workers=multiprocessing.cpu_count(),\n",
    "                sample=1e-5,seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "fname = get_tmpfile(\"my_doc2vec_model\")\n",
    "model.save(fname)\n",
    "model = Doc2Vec.load(fname)  # you can continue training with the loaded model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "vector = model.infer_vector(corpus[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01800402 -0.02171643  0.01121909 -0.01006022 -0.02468575 -0.00055146\n",
      " -0.01433296  0.00101812 -0.00539515  0.01755599 -0.01787208  0.00597149\n",
      "  0.00638365  0.02454521 -0.00664393  0.01105519 -0.01746321  0.02363307\n",
      "  0.01819221  0.00831065]\n"
     ]
    }
   ],
   "source": [
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
